<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GAN原理以及代码实现 - 嘉嘉小站</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="嘉嘉小站"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="嘉嘉小站"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="GAN（Generative Adversarial Nets）是生成模型的一种，其训练是在对抗博弈中进行的。GAN包含两个主要结构：生成器G（Generator）用于捕获数据分布规律并生成新的数据，判别器D（Discriminator）用于判断样本来自训练集还是生成器。以生成图片为例简述GAN的基本原理。 基本原理生成器生成器G接收一个随机的噪声z，通过这个噪声生成图片，记为G(z)。训练的目标"><meta property="og:type" content="blog"><meta property="og:title" content="GAN原理以及代码实现"><meta property="og:url" content="http://leoljl.github.io/2021/09/27/DCGAN/"><meta property="og:site_name" content="嘉嘉小站"><meta property="og:description" content="GAN（Generative Adversarial Nets）是生成模型的一种，其训练是在对抗博弈中进行的。GAN包含两个主要结构：生成器G（Generator）用于捕获数据分布规律并生成新的数据，判别器D（Discriminator）用于判断样本来自训练集还是生成器。以生成图片为例简述GAN的基本原理。 基本原理生成器生成器G接收一个随机的噪声z，通过这个噪声生成图片，记为G(z)。训练的目标"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://leoljl.github.io/2021/09/27/DCGAN/1.jpg"><meta property="og:image" content="http://leoljl.github.io/2021/09/27/DCGAN/2.png"><meta property="og:image" content="http://leoljl.github.io/2021/09/27/DCGAN/3.jpg"><meta property="og:image" content="http://leoljl.github.io/2021/09/27/DCGAN/5.png"><meta property="og:image" content="http://leoljl.github.io/2021/09/27/DCGAN/6.png"><meta property="og:image" content="http://leoljl.github.io/2021/09/27/DCGAN/4.jpg"><meta property="article:published_time" content="2021-09-27T11:42:56.000Z"><meta property="article:modified_time" content="2021-10-01T16:38:41.149Z"><meta property="article:author" content="Leo.L"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/2021/09/27/DCGAN/1.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://leoljl.github.io/2021/09/27/DCGAN/"},"headline":"GAN原理以及代码实现","image":["http://leoljl.github.io/2021/09/27/DCGAN/1.jpg","http://leoljl.github.io/2021/09/27/DCGAN/2.png","http://leoljl.github.io/2021/09/27/DCGAN/3.jpg","http://leoljl.github.io/2021/09/27/DCGAN/5.png","http://leoljl.github.io/2021/09/27/DCGAN/6.png","http://leoljl.github.io/2021/09/27/DCGAN/4.jpg"],"datePublished":"2021-09-27T11:42:56.000Z","dateModified":"2021-10-01T16:38:41.149Z","author":{"@type":"Person","name":"Leo.L"},"description":"GAN（Generative Adversarial Nets）是生成模型的一种，其训练是在对抗博弈中进行的。GAN包含两个主要结构：生成器G（Generator）用于捕获数据分布规律并生成新的数据，判别器D（Discriminator）用于判断样本来自训练集还是生成器。以生成图片为例简述GAN的基本原理。 基本原理生成器生成器G接收一个随机的噪声z，通过这个噪声生成图片，记为G(z)。训练的目标"}</script><link rel="canonical" href="http://leoljl.github.io/2021/09/27/DCGAN/"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/xcode.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/avatar.png" alt="嘉嘉小站" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="My Github" href="https://www.github.com/LeoLjl"><i class="fab fa-Github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>GAN原理以及代码实现</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="${date_xml(page.date)}" title="${date_xml(page.date)}">2021-09-27</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="${date_xml(page.updated)}" title="${date_xml(page.updated)}">2021-10-02</time></span></div></div><div class="content"><p>GAN（Generative Adversarial Nets）是生成模型的一种，其训练是在对抗博弈中进行的。GAN包含两个主要结构：生成器G（Generator）用于捕获数据分布规律并生成新的数据，判别器D（Discriminator）用于判断样本来自训练集还是生成器。以生成图片为例简述GAN的基本原理。</p>
<h1 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h1><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>生成器G接收一个随机的噪声z，通过这个噪声生成图片，记为G(z)。训练的目标是使得生成的图片尽可能的与数据集相似，从而骗过判别器G。</p>
<blockquote>
<p>这里输入的向量我们将其视为携带输出的某些信息，比如说手写数字为数字几，手写的潦草程度等等。由于这里我们对于输出的具体信息不做要求，只要求其能够最大程度与真实数据相似（能骗过判别器）即可。所以我们使用随机生成的向量来作为输入即可，这里面的随机输入最好是满足常见分布比如均值分布，高斯分布等。</p>
</blockquote>
<h2 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h2><p>判别器D接受一张图片x，输出标量D(x)代表x为真实图片的概率，1代表100%真实; 0代表不可能为真实图片。D为通常的网络结构，可以是Perceptron、CNN等等。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>论文中的损失函数定义如下：</p>
<div>
$$
\min_G \max_D V(D,G)=\mathbb{E}_{\boldsymbol{x}\sim p_{data}(\boldsymbol{x})}[\log D(x)] + \mathbb{E}_{\boldsymbol{z}\sim p_{z}(\boldsymbol{z})}[\log (1-D(G(z)))]
$$
</div>
该函数由两部分构成，第一部分针对真实图片，第二部分针对输入网络的噪声。函数的目标是一个minimax函数，我们分别对其进行解释。

<ul>
<li>对于真实图片，$D(x)$代表判别器认为其是真实图片的概率; 对于噪声z，$D(G(z))$代表判别器认为生成器生成的图片是真实图片的概率。</li>
<li>对于判别器D，其需要尽可能的提高分辨能力，所以其训练目标为最大$D(x)$，最小$D(G(z))$，综合起来即求$\max_D V(D)$</li>
<li>对于生成器G，其需要自己生成的图片尽可能的真实，所以其训练目标是最大化$D(G(z))$，也即$min_G V(G)$</li>
</ul>
<p>可以预想到，在理想情况下，G生成的图片可以以假乱真，$D(G(z))=0.5$。</p>
<h2 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h2><p>实际训练方法结合了Goodfellow论文中的算法以及<a target="_blank" rel="noopener" href="https://github.com/soumith/ganhacks">ganhacks</a>中的一些tricks，即将真实数据和生成数据分不同的mini-batch训练，将G的目标调整为$\max\log D(G(z))$</p>
<ol>
<li>初始化生成器G和判别器D的参数$\theta_G,\theta_D$</li>
<li>从数据集中采样$m$个样本 ${x^{(1)}, x^{(2)}, \cdots, x^{(m)}}$ ，计算损失$\log(D(x))$，得到D参数的梯度。</li>
<li>从噪声中采样$m$个噪声样本 ${z^{(1)}, z^{(2)}, \cdots, z^{(m)}}$ ，通过生成器得到$m$个生成样本 ${x^{(1)}, x^{(2)}, \cdots, x^{(m)}}$ 。计算损失$log(1-D(G(z)))$，得到D参数的梯度，将两次的梯度积累在一起并反向传播。</li>
<li>重复2-3步$k$次训练判别器D</li>
<li>用训练得到的判别器D对生成器G的输出图像做分类，计算$\log D(G(z))$求梯度并反向传播。</li>
</ol>
<p>第2-5步为1个epoch，训练时不断重复。</p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>以CIFAR-10为数据集，实现DCGAN网络。</p>
<p>首先导入一些必要的库。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.backends.cudnn <span class="keyword">as</span> cudnn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> dset</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision.utils <span class="keyword">as</span> vutils</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> HTML</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>

<p>定义一些超参数后面使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">image_size = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">nz = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.0002</span></span><br><span class="line"></span><br><span class="line">ngf = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">ndf = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">ngpu = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">beta1 = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure>



<h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><p>数据我选择的是从Google Drive下载到本地然后解压到<code>data</code>文件夹中，用<code>ImageFolder</code>方法加载数据。使用Torch自带的<code>torchvision.datasets.CelebA</code>会报错，查资料发现这个bug大家都有，遂放弃。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">dataroot = <span class="string">&quot;data&quot;</span></span><br><span class="line">dataset = dset.ImageFolder(root=dataroot,</span><br><span class="line">                           transform=transforms.Compose([</span><br><span class="line">                               transforms.Resize(image_size),</span><br><span class="line">                               transforms.CenterCrop(image_size),</span><br><span class="line">                               transforms.ToTensor(),</span><br><span class="line">                               transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>)),</span><br><span class="line">                           ]))</span><br><span class="line"></span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">True</span>, num_workers=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确定设备</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> (torch.cuda.is_available() <span class="keyword">and</span> ngpu &gt; <span class="number">0</span>) <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为方便起见，我们可视化一些数据</span></span><br><span class="line">real_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloader))</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Training Images&quot;</span>)</span><br><span class="line">plt.imshow(np.transpose(vutils.make_grid(real_batch[<span class="number">0</span>].to(device)[:<span class="number">64</span>], padding=<span class="number">2</span>, normalize=<span class="literal">True</span>).cpu(),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>

<p>得到的图像如下</p>
<img src="/2021/09/27/DCGAN/1.jpg" class="" title="This is an image.">

<h2 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h2><h3 id="生成器-1"><a href="#生成器-1" class="headerlink" title="生成器"></a>生成器</h3><p>首先定义生成器结构，参考DCGAN文献中的结构如图。z为从噪声中采样得到的100维向量，经过几次上采样，得到一个$3\times 64\times 64$的Tensor，也就是生成的RGB图像。</p>
<img src="/2021/09/27/DCGAN/2.png" class="" title="This is an image.">

<p>代码如下，为了节省算力，将Channel数都减半了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># ngf设置为64</span></span><br><span class="line">            nn.ConvTranspose2d(nz, ngf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            <span class="comment">#除最后一个ConvTranspose层，都有一个BatchNorm层</span></span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">8</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">8</span>, ngf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">4</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">4</span>, ngf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">2</span>, ngf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            </span><br><span class="line">            nn.ConvTranspose2d(ngf, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.main(x)</span><br><span class="line">    </span><br><span class="line">G = Generator().to(device)</span><br></pre></td></tr></table></figure>



<h3 id="判别器-1"><a href="#判别器-1" class="headerlink" title="判别器"></a>判别器</h3><p>判别器D负责判断输入的图像是生成器生成的还是真实图像。它接收一个$3\times 64\times 64$的输入图像，经过一系列卷积操作输出概率。论文中提到最好用strided convolution而非用pooling layer下采样。该网络结构借鉴于PyTorch官网。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># ndf设置为64</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, ndf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 尺寸 (ndf) x 32 x 32</span></span><br><span class="line">            nn.Conv2d(ndf, ndf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 尺寸 (ndf*2) x 16 x 16</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">2</span>, ndf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 尺寸 (ndf*4) x 8 x 8</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">4</span>, ndf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">8</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># 尺寸 (ndf*8) x 4 x 4</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">8</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.main(x)</span><br><span class="line"></span><br><span class="line">D = Discriminator().to(device)</span><br></pre></td></tr></table></figure>



<h3 id="初始器"><a href="#初始器" class="headerlink" title="初始器"></a>初始器</h3><p>论文作者提出网络初始参数采样自平均值0，标准差0.02的高斯分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">net</span>):</span></span><br><span class="line">    classname = net.__class__.__name__</span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">&#x27;Conv&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">        nn.init.normal_(net.weight.data, <span class="number">0.0</span>, <span class="number">0.02</span>)</span><br><span class="line">    <span class="keyword">elif</span> classname.find(<span class="string">&#x27;BatchNorm&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">        nn.init.normal_(net.weight.data, <span class="number">1.0</span>, <span class="number">0.02</span>)</span><br><span class="line">        nn.init.constant_(net.bias.data, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">G.apply(init_weights)</span><br><span class="line">D.apply(init_weights)</span><br><span class="line"><span class="built_in">print</span>(G)</span><br><span class="line"><span class="built_in">print</span>(D)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Generator(</span><br><span class="line">  (main): Sequential(</span><br><span class="line">    (0): ConvTranspose2d(100, 512, kernel_size&#x3D;(4, 4), stride&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (1): BatchNorm2d(512, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">    (2): ReLU(inplace&#x3D;True)</span><br><span class="line">    (3): ConvTranspose2d(512, 256, kernel_size&#x3D;(4, 4), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (4): BatchNorm2d(256, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">    (5): ReLU(inplace&#x3D;True)</span><br><span class="line">    (6): ConvTranspose2d(256, 128, kernel_size&#x3D;(4, 4), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (7): BatchNorm2d(128, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">    (8): ReLU(inplace&#x3D;True)</span><br><span class="line">    (9): ConvTranspose2d(128, 64, kernel_size&#x3D;(4, 4), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (10): BatchNorm2d(64, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">    (11): ReLU(inplace&#x3D;True)</span><br><span class="line">    (12): ConvTranspose2d(64, 3, kernel_size&#x3D;(4, 4), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (13): Tanh()</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line">Discriminator(</span><br><span class="line">  (main): Sequential(</span><br><span class="line">    (0): Conv2d(3, 64, kernel_size&#x3D;(4, 4), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (1): LeakyReLU(negative_slope&#x3D;0.2, inplace&#x3D;True)</span><br><span class="line">    (2): Conv2d(64, 128, kernel_size&#x3D;(4, 4), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (3): BatchNorm2d(128, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">    (4): LeakyReLU(negative_slope&#x3D;0.2, inplace&#x3D;True)</span><br><span class="line">    (5): Conv2d(128, 256, kernel_size&#x3D;(4, 4), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (6): BatchNorm2d(256, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">    (7): LeakyReLU(negative_slope&#x3D;0.2, inplace&#x3D;True)</span><br><span class="line">    (8): Conv2d(256, 512, kernel_size&#x3D;(4, 4), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (9): BatchNorm2d(512, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)</span><br><span class="line">    (10): LeakyReLU(negative_slope&#x3D;0.2, inplace&#x3D;True)</span><br><span class="line">    (11): Conv2d(512, 1, kernel_size&#x3D;(4, 4), stride&#x3D;(1, 1), bias&#x3D;False)</span><br><span class="line">    (12): Sigmoid()</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="损失函数和优化器"><a href="#损失函数和优化器" class="headerlink" title="损失函数和优化器"></a>损失函数和优化器</h2><p>损失函数选择交叉熵，在PyTorch中定义为</p>
<div>
$$
l = -[y\log(x) + (1-y)\log(1-x)]
$$
</div>
这个函数与目标函数形式类似，我们可以通过设定$y$来选择使用损失函数的$\log(x)$部分还是$\log(1-x)$部分。

<p>我们将真实图像的标签设置为1，生成图像标签设置为0。为D与G分别定义一个优化器，均为Adam，学习率0.0002，beta1=0.5</p>
<p>我们在每个epoch结束后向生成器输入一个固定的噪声，观察它的输出随着epoch的增加的变化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line"><span class="comment"># 固定的噪声</span></span><br><span class="line">fixed_noise = torch.randn(<span class="number">64</span>, nz, <span class="number">1</span>, <span class="number">1</span>, device=device)</span><br><span class="line"></span><br><span class="line">real_label = <span class="number">1.</span></span><br><span class="line">fake_label = <span class="number">0.</span></span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line">optimizerD = optim.Adam(D.parameters(), lr=lr, betas=(beta1, <span class="number">0.999</span>))</span><br><span class="line">optimizerG = optim.Adam(G.parameters(), lr=lr, betas=(beta1, <span class="number">0.999</span>))</span><br></pre></td></tr></table></figure>

<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>训练过程如原理部分所提到，代码只是将其实现了一遍。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于记录训练结果</span></span><br><span class="line">img_list = []</span><br><span class="line">G_losses = []</span><br><span class="line">D_losses = []</span><br><span class="line">iters = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Starting Training Loop...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># Step 1: Update D network: maximize log(D(x)) + log(1 - D(G(z)))        </span></span><br><span class="line">        <span class="comment">## 用全部为真实图片的batch</span></span><br><span class="line">        D.zero_grad()</span><br><span class="line">        <span class="comment"># 加载进gpu</span></span><br><span class="line">        data_gpu = data[<span class="number">0</span>].to(device)</span><br><span class="line">        b_size = data_gpu.size(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 所有的图片标签均为1, 计算的损失函数为-log(D(x))</span></span><br><span class="line">        label = torch.full((b_size,), real_label, dtype=torch.<span class="built_in">float</span>, device=device) </span><br><span class="line">        <span class="comment"># 将数据forward pass</span></span><br><span class="line">        output = D(data_gpu).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算loss</span></span><br><span class="line">        errD_real = criterion(output, label)</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        errD_real.backward()</span><br><span class="line">        D_x = output.mean().item()</span><br><span class="line"></span><br><span class="line">        <span class="comment">## 用全部是生成图片的batch</span></span><br><span class="line">        <span class="comment"># 生成假图片</span></span><br><span class="line">        noise = torch.randn(b_size, nz, <span class="number">1</span>, <span class="number">1</span>, device=device)</span><br><span class="line">        fake = G(noise)</span><br><span class="line">        <span class="comment"># 将标签改为0，计算的损失函数为-log(1-D(G(z)))</span></span><br><span class="line">        label.fill_(fake_label)</span><br><span class="line">        <span class="comment"># 一定要加fake.detach()，不然第二步无法反向传播</span></span><br><span class="line">        output = D(fake.detach()).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算损失函数</span></span><br><span class="line">        errD_fake = criterion(output, label)</span><br><span class="line">        <span class="comment"># 计算梯度，与上个部分算得的梯度相加</span></span><br><span class="line">        errD_fake.backward()</span><br><span class="line">        D_G_z1 = output.mean().item()</span><br><span class="line">        <span class="comment"># 计算D的总损失</span></span><br><span class="line">        errD = errD_real + errD_fake</span><br><span class="line">        optimizerD.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Update G network: maximize log(D(G(z)))</span></span><br><span class="line">        G.zero_grad()</span><br><span class="line">        label.fill_(real_label)  <span class="comment"># label填1,这样计算的损失函数为-log(D(G(z)))</span></span><br><span class="line">        <span class="comment"># 将生成器生成的图片输入分别器，得到输出</span></span><br><span class="line">        output = D(fake).view(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算生成器的损失</span></span><br><span class="line">        errG = criterion(output, label)</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        errG.backward()</span><br><span class="line">        D_G_z2 = output.mean().item()</span><br><span class="line">        optimizerG.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出训练情况</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f&#x27;</span></span><br><span class="line">                  % (epoch, num_epochs, i, <span class="built_in">len</span>(dataloader),</span><br><span class="line">                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 储存损失函数的值用于画图</span></span><br><span class="line">        G_losses.append(errG.item())</span><br><span class="line">        D_losses.append(errD.item())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 观察生成器在给定输入下的输出随着epoch数增加的变化</span></span><br><span class="line">        <span class="keyword">if</span> (iters % <span class="number">1500</span> == <span class="number">0</span>) <span class="keyword">or</span> ((epoch == num_epochs-<span class="number">1</span>) <span class="keyword">and</span> (i == <span class="built_in">len</span>(dataloader)-<span class="number">1</span>)):</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                fake = G(fixed_noise).detach().cpu()</span><br><span class="line">            img_list.append(vutils.make_grid(fake, padding=<span class="number">2</span>, normalize=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">        iters += <span class="number">1</span></span><br><span class="line">  </span><br></pre></td></tr></table></figure>

<p>截取部分输出如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Starting Training Loop...</span><br><span class="line">[0&#x2F;16][0&#x2F;1344]	Loss_D: 1.9634	Loss_G: 4.5095	D(x): 0.4211	D(G(z)): 0.5242 &#x2F; 0.0159</span><br><span class="line">[0&#x2F;16][100&#x2F;1344]	Loss_D: 0.3319	Loss_G: 6.5696	D(x): 0.9065	D(G(z)): 0.1146 &#x2F; 0.0058</span><br><span class="line">[0&#x2F;16][200&#x2F;1344]	Loss_D: 0.8147	Loss_G: 8.3612	D(x): 0.9388	D(G(z)): 0.4045 &#x2F; 0.0008</span><br><span class="line">[0&#x2F;16][300&#x2F;1344]	Loss_D: 1.3598	Loss_G: 7.1813	D(x): 0.9571	D(G(z)): 0.6396 &#x2F; 0.0034</span><br><span class="line">[0&#x2F;16][400&#x2F;1344]	Loss_D: 1.1145	Loss_G: 7.4710	D(x): 0.9355	D(G(z)): 0.5557 &#x2F; 0.0025</span><br><span class="line">[0&#x2F;16][500&#x2F;1344]	Loss_D: 0.4718	Loss_G: 4.6667	D(x): 0.7850	D(G(z)): 0.0928 &#x2F; 0.0221</span><br><span class="line">[0&#x2F;16][600&#x2F;1344]	Loss_D: 0.4587	Loss_G: 3.8398	D(x): 0.8438	D(G(z)): 0.1818 &#x2F; 0.0434</span><br><span class="line">[0&#x2F;16][700&#x2F;1344]	Loss_D: 0.4853	Loss_G: 4.4762	D(x): 0.8795	D(G(z)): 0.2440 &#x2F; 0.0224</span><br><span class="line">[0&#x2F;16][800&#x2F;1344]	Loss_D: 0.4169	Loss_G: 3.6308	D(x): 0.7731	D(G(z)): 0.0740 &#x2F; 0.0469</span><br><span class="line">[0&#x2F;16][900&#x2F;1344]	Loss_D: 0.1671	Loss_G: 5.2397	D(x): 0.8985	D(G(z)): 0.0384 &#x2F; 0.0102</span><br><span class="line">[0&#x2F;16][1000&#x2F;1344]	Loss_D: 0.5116	Loss_G: 4.0730	D(x): 0.7616	D(G(z)): 0.1442 &#x2F; 0.0312</span><br><span class="line">[0&#x2F;16][1100&#x2F;1344]	Loss_D: 0.6857	Loss_G: 4.2473	D(x): 0.6337	D(G(z)): 0.0170 &#x2F; 0.0272</span><br><span class="line">[0&#x2F;16][1200&#x2F;1344]	Loss_D: 0.4163	Loss_G: 4.2029	D(x): 0.7515	D(G(z)): 0.0479 &#x2F; 0.0308</span><br><span class="line">[0&#x2F;16][1300&#x2F;1344]	Loss_D: 0.5726	Loss_G: 3.6670	D(x): 0.7889	D(G(z)): 0.2219 &#x2F; 0.0416</span><br><span class="line">[1&#x2F;16][0&#x2F;1344]	Loss_D: 0.7348	Loss_G: 6.1066	D(x): 0.9219	D(G(z)): 0.4060 &#x2F; 0.0045</span><br><span class="line">...</span><br><span class="line">[15&#x2F;16][1000&#x2F;1344]	Loss_D: 0.2496	Loss_G: 3.4040	D(x): 0.8612	D(G(z)): 0.0686 &#x2F; 0.0578</span><br><span class="line">[15&#x2F;16][1100&#x2F;1344]	Loss_D: 0.8923	Loss_G: 1.8258	D(x): 0.5667	D(G(z)): 0.1154 &#x2F; 0.2363</span><br><span class="line">[15&#x2F;16][1200&#x2F;1344]	Loss_D: 0.2764	Loss_G: 4.7261	D(x): 0.9499	D(G(z)): 0.1727 &#x2F; 0.0137</span><br><span class="line">[15&#x2F;16][1300&#x2F;1344]	Loss_D: 0.6088	Loss_G: 5.4057	D(x): 0.9769	D(G(z)): 0.3796 &#x2F; 0.0097</span><br></pre></td></tr></table></figure>



<h1 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h1><p>看见结果初步感觉训练结果应该不对劲，理想状态下D(x)应当趋向于0.5，即无法分辨真实与虚假图像。</p>
<p>首先画出D和G的loss随着训练的改变。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Generator and Discriminator Loss During Training&quot;</span>)</span><br><span class="line">plt.plot(G_losses,label=<span class="string">&quot;G&quot;</span>)</span><br><span class="line">plt.plot(D_losses,label=<span class="string">&quot;D&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;iterations&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="/2021/09/27/DCGAN/3.jpg" class="" title="This is an image.">

<p>接着看一看对于固定输入，生成器的输出随着iteration增加的改变。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#%%capture</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> animation</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">ims = [[plt.imshow(np.transpose(i,(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)), animated=<span class="literal">True</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> img_list]</span><br><span class="line">ani = animation.ArtistAnimation(fig, ims, interval=<span class="number">1000</span>, repeat_delay=<span class="number">1000</span>, blit=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">HTML(ani.to_jshtml())</span><br></pre></td></tr></table></figure>

<p>得到一段动画，截取最开始的输出和最后的输出如下</p>
<img src="/2021/09/27/DCGAN/5.png" class="" title="This is an image.">

<img src="/2021/09/27/DCGAN/6.png" class="" title="This is an image.">

<p>可以看出生成的人脸有了一定的改善，但效果还是很糟糕。具体的超参数还需要调整。</p>
<p>最后，对比一番真实人脸和生成人脸，可以发现有很大的误差。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 真实图片</span></span><br><span class="line">real_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloader))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Real Images&quot;</span>)</span><br><span class="line">plt.imshow(np.transpose(vutils.make_grid(real_batch[<span class="number">0</span>].to(device)[:<span class="number">64</span>], padding=<span class="number">5</span>, normalize=<span class="literal">True</span>).cpu(),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成图片</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Fake Images&quot;</span>)</span><br><span class="line">plt.imshow(np.transpose(img_list[-<span class="number">1</span>],(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="/2021/09/27/DCGAN/4.jpg" class="" title="This is an image.">

<h1 id="踩过的坑"><a href="#踩过的坑" class="headerlink" title="踩过的坑"></a>踩过的坑</h1><ol>
<li>epoch一开始设置为64，在到达第34个epoch的时候出现问题，输出如下</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[33&#x2F;64][0&#x2F;1583]	Loss_D: 0.0413	Loss_G: 5.8435	D(x): 0.9725	D(G(z)): 0.0080 &#x2F; 0.0126</span><br><span class="line">[33&#x2F;64][100&#x2F;1583]	Loss_D: 0.2360	Loss_G: 3.3545	D(x): 0.8402	D(G(z)): 0.0070 &#x2F; 0.1269</span><br><span class="line">[33&#x2F;64][200&#x2F;1583]	Loss_D: 0.0288	Loss_G: 6.3076	D(x): 0.9898	D(G(z)): 0.0165 &#x2F; 0.0065</span><br><span class="line">[33&#x2F;64][300&#x2F;1583]	Loss_D: 0.0714	Loss_G: 5.9589	D(x): 0.9574	D(G(z)): 0.0144 &#x2F; 0.0119</span><br><span class="line">[33&#x2F;64][400&#x2F;1583]	Loss_D: 0.0526	Loss_G: 5.7749	D(x): 0.9657	D(G(z)): 0.0083 &#x2F; 0.0146</span><br><span class="line">[33&#x2F;64][500&#x2F;1583]	Loss_D: 0.0645	Loss_G: 7.1439	D(x): 0.9937	D(G(z)): 0.0521 &#x2F; 0.0021</span><br><span class="line">[33&#x2F;64][600&#x2F;1583]	Loss_D: 0.0893	Loss_G: 7.5577	D(x): 0.9774	D(G(z)): 0.0465 &#x2F; 0.0026</span><br><span class="line">[33&#x2F;64][700&#x2F;1583]	Loss_D: 0.0616	Loss_G: 7.9219	D(x): 0.9883	D(G(z)): 0.0426 &#x2F; 0.0023</span><br><span class="line">[33&#x2F;64][800&#x2F;1583]	Loss_D: 0.0697	Loss_G: 6.6769	D(x): 0.9751	D(G(z)): 0.0249 &#x2F; 0.0049</span><br><span class="line">[33&#x2F;64][900&#x2F;1583]	Loss_D: 0.0596	Loss_G: 5.8319	D(x): 0.9944	D(G(z)): 0.0467 &#x2F; 0.0078</span><br><span class="line">[33&#x2F;64][1000&#x2F;1583]	Loss_D: 0.2075	Loss_G: 6.8002	D(x): 0.8620	D(G(z)): 0.0072 &#x2F; 0.0142</span><br><span class="line">[33&#x2F;64][1100&#x2F;1583]	Loss_D: 0.0400	Loss_G: 5.7057	D(x): 0.9850	D(G(z)): 0.0188 &#x2F; 0.0122</span><br><span class="line">[33&#x2F;64][1200&#x2F;1583]	Loss_D: 0.0311	Loss_G: 7.8273	D(x): 0.9897	D(G(z)): 0.0125 &#x2F; 0.0023</span><br><span class="line">[33&#x2F;64][1300&#x2F;1583]	Loss_D: 0.0550	Loss_G: 5.3413	D(x): 0.9764	D(G(z)): 0.0252 &#x2F; 0.0132</span><br><span class="line">[33&#x2F;64][1400&#x2F;1583]	Loss_D: 0.0576	Loss_G: 10.7131	D(x): 0.9515	D(G(z)): 0.0021 &#x2F; 0.0003</span><br><span class="line">[33&#x2F;64][1500&#x2F;1583]	Loss_D: 0.4995	Loss_G: 10.1190	D(x): 0.9986	D(G(z)): 0.2778 &#x2F; 0.0002</span><br><span class="line">[34&#x2F;64][0&#x2F;1583]	Loss_D: 0.2651	Loss_G: 6.4838	D(x): 0.8740	D(G(z)): 0.0752 &#x2F; 0.0063</span><br><span class="line">[34&#x2F;64][100&#x2F;1583]	Loss_D: 0.0746	Loss_G: 7.1531	D(x): 0.9667	D(G(z)): 0.0241 &#x2F; 0.0043</span><br><span class="line">[34&#x2F;64][200&#x2F;1583]	Loss_D: 0.0262	Loss_G: 6.4364	D(x): 0.9858	D(G(z)): 0.0110 &#x2F; 0.0055</span><br><span class="line">[34&#x2F;64][300&#x2F;1583]	Loss_D: 0.1436	Loss_G: 5.4750	D(x): 0.9047	D(G(z)): 0.0191 &#x2F; 0.0280</span><br><span class="line">[34&#x2F;64][400&#x2F;1583]	Loss_D: 0.0332	Loss_G: 6.3144	D(x): 0.9865	D(G(z)): 0.0175 &#x2F; 0.0111</span><br><span class="line">[34&#x2F;64][500&#x2F;1583]	Loss_D: 0.0632	Loss_G: 9.2094	D(x): 0.9674	D(G(z)): 0.0190 &#x2F; 0.0005</span><br><span class="line">[34&#x2F;64][600&#x2F;1583]	Loss_D: 0.0000	Loss_G: 67.3240	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][700&#x2F;1583]	Loss_D: 0.0001	Loss_G: 66.4839	D(x): 0.9999	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][800&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.1828	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][900&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.3180	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][1000&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.2066	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][1100&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.5655	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][1200&#x2F;1583]	Loss_D: 0.0000	Loss_G: 67.4126	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][1300&#x2F;1583]	Loss_D: 0.0000	Loss_G: 65.4057	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][1400&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.1651	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[34&#x2F;64][1500&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.4172	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[35&#x2F;64][0&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.3567	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[35&#x2F;64][100&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.4605	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[35&#x2F;64][200&#x2F;1583]	Loss_D: 0.0000	Loss_G: 65.9061	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[35&#x2F;64][300&#x2F;1583]	Loss_D: 0.0000	Loss_G: 65.9909	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[35&#x2F;64][400&#x2F;1583]	Loss_D: 0.0000	Loss_G: 65.6323	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[35&#x2F;64][500&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.3318	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br><span class="line">[35&#x2F;64][600&#x2F;1583]	Loss_D: 0.0000	Loss_G: 66.1391	D(x): 1.0000	D(G(z)): 0.0000 &#x2F; 0.0000</span><br></pre></td></tr></table></figure>

<p>原因猜测：参数没调好，导致训练走向为判别器越来越强，生成器的生成能力跟不上。</p>
<ol start="2">
<li>一开始输出就崩了</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Starting Training Loop...</span><br><span class="line">[0&#x2F;16][0&#x2F;1344]	Loss_D: 2.3426	Loss_G: 17.7673	D(x): 0.2791	D(G(z)): 0.4526 &#x2F; 0.0000</span><br><span class="line">[0&#x2F;16][100&#x2F;1344]	Loss_D: 100.0000	Loss_G: 0.0000	D(x): 1.0000	D(G(z)): 1.0000 &#x2F; 1.0000</span><br><span class="line">[0&#x2F;16][200&#x2F;1344]	Loss_D: 100.0000	Loss_G: 0.0000	D(x): 1.0000	D(G(z)): 1.0000 &#x2F; 1.0000</span><br><span class="line">[0&#x2F;16][300&#x2F;1344]	Loss_D: 100.0000	Loss_G: 0.0000	D(x): 1.0000	D(G(z)): 1.0000 &#x2F; 1.0000</span><br><span class="line">[0&#x2F;16][400&#x2F;1344]	Loss_D: 100.0000	Loss_G: 0.0000	D(x): 1.0000	D(G(z)): 1.0000 &#x2F; 1.0000</span><br></pre></td></tr></table></figure>

<p>原因：learning_rate手残把0.0002写成了0.002。导致训练走向为生成器越来越强，判别器判别能力跟不上。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html</a></li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>GAN原理以及代码实现</p><p><a href="http://leoljl.github.io/2021/09/27/DCGAN/">http://leoljl.github.io/2021/09/27/DCGAN/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Leo.L</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-09-27</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-10-02</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/09/25/Torch-mnist/"><span class="level-item">用Torch搭建手写字体识别模型</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/photo.jpg" alt="Leo.L"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Leo.L</p><p class="is-size-6 is-block">Undergrad@XiDian University</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Xi&#039;an, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">3</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/LeoLjl" target="_blank" rel="noopener">Follow</a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#基本原理"><span class="level-left"><span class="level-item">1</span><span class="level-item">基本原理</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#生成器"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">生成器</span></span></a></li><li><a class="level is-mobile" href="#判别器"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">判别器</span></span></a></li><li><a class="level is-mobile" href="#损失函数"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">损失函数</span></span></a></li><li><a class="level is-mobile" href="#训练方法"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">训练方法</span></span></a></li></ul></li><li><a class="level is-mobile" href="#代码实现"><span class="level-left"><span class="level-item">2</span><span class="level-item">代码实现</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#准备数据"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">准备数据</span></span></a></li><li><a class="level is-mobile" href="#定义网络"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">定义网络</span></span></a></li><li><a class="level is-mobile" href="#损失函数和优化器"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">损失函数和优化器</span></span></a></li><li><a class="level is-mobile" href="#训练"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">训练</span></span></a></li></ul></li><li><a class="level is-mobile" href="#训练结果"><span class="level-left"><span class="level-item">3</span><span class="level-item">训练结果</span></span></a></li><li><a class="level is-mobile" href="#踩过的坑"><span class="level-left"><span class="level-item">4</span><span class="level-item">踩过的坑</span></span></a></li><li><a class="level is-mobile" href="#Reference"><span class="level-left"><span class="level-item">5</span><span class="level-item">Reference</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://levitate-qian.github.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">钱佬博客</span></span><span class="level-right"><span class="level-item tag">levitate-qian.github.io</span></span></a></li><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">September 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/demo/"><span class="tag">demo</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/regex/"><span class="tag">regex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tutorial/"><span class="tag">tutorial</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-27T11:42:56.000Z">2021-09-27</time></p><p class="title"><a href="/2021/09/27/DCGAN/">GAN原理以及代码实现</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-25T14:06:06.000Z">2021-09-25</time></p><p class="title"><a href="/2021/09/25/Torch-mnist/">用Torch搭建手写字体识别模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-09T09:54:24.000Z">2021-05-09</time></p><p class="title"><a href="/2021/05/09/regex/">正则表达式（Regular expression）</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-25T15:44:19.000Z">2021-04-25</time></p><p class="title"><a href="/2021/04/25/README/">README</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-25T10:43:19.000Z">2021-04-25</time></p><p class="title"><a href="/2021/04/25/code-demo/">code-demo</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/avatar.png" alt="嘉嘉小站" height="28"></a><p class="is-size-7"><span>&copy; 2021 Leo.L</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> </a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="My GitHub" href="https://www.github.com/LeoLjl"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>